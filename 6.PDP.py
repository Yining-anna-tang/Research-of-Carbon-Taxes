# å‘½åç®€å†™å¤–éƒ¨åº“
import pandas as pd
# å¯¼å…¥numpyåº“ï¼Œç®€ç§°ä¸ºnp
import numpy as np
# å¯¼å…¥seabornåº“ï¼Œç®€ç§°ä¸ºsns
import seaborn as sns
# å¯¼å…¥matplotlib.pyplotæ¨¡å—ï¼Œç®€ç§°ä¸ºplt
import matplotlib.pyplot as plt

plt.rcParams['font.sans-serif'] = 'Times New Roman'
plt.rcParams['axes.unicode_minus'] = False


# 1.è¯»å–æ•°æ®ï¼Œè®¾ç½®å˜é‡
data = pd.read_csv(r'/Users/yiningtang/PycharmProjects/pythonProject1/WTP.csv',encoding = "GBK")
df = pd.DataFrame(data)
from sklearn.model_selection import train_test_split, KFold

X = df.drop(['Y'],axis=1)
y = df['Y']

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.metrics import root_mean_squared_error
from catboost import CatBoostRegressor

# CatBoostæ¨¡å‹å‚æ•°
params_cat = {
    'learning_rate': 0.01,       # å­¦ä¹ ç‡ï¼Œæ§åˆ¶æ¯ä¸€æ­¥çš„æ­¥é•¿ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚å…¸å‹å€¼èŒƒå›´ï¼š0.01 - 0.1
    'iterations': 1000,          # å¼±å­¦ä¹ å™¨ï¼ˆå†³ç­–æ ‘ï¼‰çš„æ•°é‡
    'depth': 6,                  # å†³ç­–æ ‘çš„æ·±åº¦ï¼Œæ§åˆ¶æ¨¡å‹å¤æ‚åº¦
    'eval_metric': 'RMSE',       # è¯„ä¼°æŒ‡æ ‡ï¼Œè¿™é‡Œä½¿ç”¨å‡æ–¹æ ¹è¯¯å·®ï¼ˆRoot Mean Squared Errorï¼Œç®€ç§°RMSEï¼‰
    'random_seed': 42,           # éšæœºç§å­ï¼Œç”¨äºé‡ç°æ¨¡å‹çš„ç»“æœ
    'verbose': 500               # æ§åˆ¶CatBoostè¾“å‡ºä¿¡æ¯çš„è¯¦ç»†ç¨‹åº¦ï¼Œæ¯100æ¬¡è¿­ä»£è¾“å‡ºä¸€æ¬¡
}

# å‡†å¤‡kæŠ˜äº¤å‰éªŒè¯
kf = KFold(n_splits=5, shuffle=True, random_state=42)
scores = []
best_score = np.inf
best_model = None

# äº¤å‰éªŒè¯
for fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):
    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]
    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]

    model = CatBoostRegressor(**params_cat)
    model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold), early_stopping_rounds=100)

    # é¢„æµ‹å¹¶è®¡ç®—å¾—åˆ†
    y_val_pred = model.predict(X_val_fold)
    score = root_mean_squared_error(y_val_fold, y_val_pred)  # RMSE

    scores.append(score)
    print(f'ç¬¬ {fold + 1} æŠ˜ RMSE: {score}')

    # ä¿å­˜å¾—åˆ†æœ€å¥½çš„æ¨¡å‹
    if score < best_score:
        best_score = score
        best_model = model

print(f'Best RMSE: {best_score}')


# æ¨¡å‹è¯„ä¼°
from sklearn import metrics
# é¢„æµ‹
y_pred_four = best_model.predict(X_test)

y_pred_list = y_pred_four.tolist()
mse = metrics.mean_squared_error(y_test, y_pred_list)
rmse = np.sqrt(mse)
mae = metrics.mean_absolute_error(y_test, y_pred_list)
r2 = metrics.r2_score(y_test, y_pred_list)

print("å‡æ–¹è¯¯å·® (MSE):", mse)
print("å‡æ–¹æ ¹è¯¯å·® (RMSE):", rmse)
print("å¹³å‡ç»å¯¹è¯¯å·® (MAE):", mae)
print("æ‹Ÿåˆä¼˜åº¦ (R-squared):", r2)

# æ¨¡å‹è§£é‡Š
# shapåº“å¯¼å…¥
import shap
# æ„å»º shapè§£é‡Šå™¨
explainer = shap.TreeExplainer(best_model)
# è®¡ç®—æµ‹è¯•é›†çš„shapå€¼
shap_values = explainer.shap_values(X_test)
# ç‰¹å¾æ ‡ç­¾
labels = X_test.columns
plt.rcParams['font.family'] = 'serif'
plt.rcParams['font.serif'] = 'Times new Roman'
plt.rcParams['font.size'] = 13

# ç»˜åˆ¶PDPï¼ˆéƒ¨åˆ†ä¾èµ–å›¾ï¼‰ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—ğŸ’—
shap.dependence_plot('ILE', shap_values, X_test, interaction_index='SEP', show=False)
plt.savefig('Y4-PDP-1.png', dpi=1000, format='png')
plt.show()
plt.figure()


